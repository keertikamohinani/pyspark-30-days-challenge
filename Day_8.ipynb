{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM6YQJPnsZ0KAY8mcyMvpj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR7YRJ-AId3E",
        "outputId": "d4fc94c6-f652-4ae0-ff7a-52df0c96a915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.5.0\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.5.0) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=fa7d6d3b8868eedbf55b30775e26c34b6f76c8469d5c624e28e89d545ce96945\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: findspark, pyspark\n",
            "Successfully installed findspark-2.0.1 pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.5.0 findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install delta-spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goaTy4-eKd8M",
        "outputId": "3e83ae57-a8c8-454f-c637-f65db03f2f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting delta-spark\n",
            "  Downloading delta_spark-3.1.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pyspark<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from delta-spark) (3.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from delta-spark) (7.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (3.18.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark<3.6.0,>=3.5.0->delta-spark) (0.10.9.7)\n",
            "Installing collected packages: delta-spark\n",
            "Successfully installed delta-spark-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark --packages com.databricks:spark-xml_2.12:0.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "VMlnCP57gxDf",
        "outputId": "07923dfb-2c52-4f83-8eba-fa6f32746943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-7-b577ed9b5509>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-b577ed9b5509>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pyspark --packages com.databricks:spark-xml_2.12:0.15.0\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n"
      ],
      "metadata": {
        "id": "hnekmsc-JFO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta import *\n",
        "\n",
        "def _create_delta_spark():\n",
        "  from pyspark.sql import SparkSession\n",
        "  from delta import configure_spark_with_delta_pip\n",
        "  builder = SparkSession.builder.appName(\"DeltaLakeApp\") \\\n",
        "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
        "  .config(\"spark.jars.packages\",\"io.delta:delta-core_2.12:2.0.0\")\\\n",
        "  .config(\"spark.jars.packages\", \"com.databricks:spark-xml_2.12:0.13.0\")\n",
        "  return configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "\n",
        "spark = _create_delta_spark()"
      ],
      "metadata": {
        "id": "ef-vbocwJHN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Hv54egMlJRtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_metadata_df = spark.read.csv(\"/content/sample_data/movies_metadata.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "eXexgyuCJNXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_metadata_df.printSchema()"
      ],
      "metadata": {
        "id": "baujHHCsmcUB",
        "outputId": "f754f2c0-0581-479f-bad9-ab0ba6a5456f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- adult: string (nullable = true)\n",
            " |-- belongs_to_collection: string (nullable = true)\n",
            " |-- budget: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- homepage: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- imdb_id: string (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: string (nullable = true)\n",
            " |-- poster_path: string (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- release_date: string (nullable = true)\n",
            " |-- revenue: string (nullable = true)\n",
            " |-- runtime: string (nullable = true)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- tagline: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- video: string (nullable = true)\n",
            " |-- vote_average: string (nullable = true)\n",
            " |-- vote_count: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_metadata_df.write.format('xml').save('/content/sample_data/movies_metadata/')"
      ],
      "metadata": {
        "id": "ekIFRcRNS_JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_metadata_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac3QBraXfSUr",
        "outputId": "a7c2deee-03f5-4c56-feb2-60973dee7d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7667"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_metadata_df = spark.read.format('delta').load('/content/sample_data/movies_metadata/')"
      ],
      "metadata": {
        "id": "KhD-NUCbe_Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df = spark.read.csv(\"/content/sample_data/ratings.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "dX2egzyc8erN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "links_df = spark.read.csv(\"/content/sample_data/links.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "vuPwSIPDciGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"XMLExample\").getOrCreate()\n",
        "\n",
        "df = spark.read.format(\"xml\")\\\n",
        "               .option(\"rowTag\", \"movie\")\\\n",
        "               .load(\"movies.xml\")\n"
      ],
      "metadata": {
        "id": "exutWlzLe2xH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}