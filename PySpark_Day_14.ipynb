{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgvRajGhGjFSZClTefEnol"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXSqKcWnmx3M",
        "outputId": "bd7f357d-02f7-4958-fc8e-2a4c9d0732e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.5.0\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.5.0) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=86c22e3f5f6b071d555cacc0c5a0d337e16a541124c4af20756b01815b38538e\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: findspark, pyspark\n",
            "Successfully installed findspark-2.0.1 pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.5.0 findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "QDReOgODnRws"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Day14\").getOrCreate()"
      ],
      "metadata": {
        "id": "J3go49bWnVmx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = spark.read.csv(\"sample_data/movies_metadata.csv\", header = True, inferSchema = True)"
      ],
      "metadata": {
        "id": "7XTU0_ax1hrZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
        "\n",
        "ratings_schema = StructType([\n",
        "    StructField(\"userId\", IntegerType(), True),\n",
        "    StructField(\"movieId\", IntegerType(), True),\n",
        "    StructField(\"rating\", DoubleType(), True),\n",
        "    StructField(\"timestamp\", IntegerType(), True)  # Changed to TimestampType\n",
        "])\n"
      ],
      "metadata": {
        "id": "G4mTQsbD6BQ_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df = spark.read.csv(\"sample_data/ratings.csv\", header=True, schema = ratings_schema)\n",
        "ratings_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lbVUgDennD7",
        "outputId": "25469729-724e-483b-de42-f9cc1a1dbe81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    110|   1.0|1425941529|\n",
            "|     1|    147|   4.5|1425942435|\n",
            "|     1|    858|   5.0|1425941523|\n",
            "|     1|   1221|   5.0|1425941546|\n",
            "|     1|   1246|   5.0|1425941556|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9upCZ4CDc7zE",
        "outputId": "4927424d-cc7d-4e6d-d2e9-173250ed7d80"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_and_ratings = movies_df.join(ratings_df, movies_df['id'] == ratings_df['movieId'], 'inner')\n"
      ],
      "metadata": {
        "id": "JH1T-ktk2M0R"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "best_rated_by_genre = movies_and_ratings.groupBy(\"genres\").avg(\"rating\").orderBy(desc(\"avg(rating)\"))\n",
        "\n",
        "best_rated_by_genre.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTpAKGvR1Yc2",
        "outputId": "343aa19a-30df-4d3c-f91a-19b4233dc8db"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|              genres|       avg(rating)|\n",
            "+--------------------+------------------+\n",
            "|[{'id': 12, 'name...|               4.5|\n",
            "|[{'id': 10749, 'n...|               4.5|\n",
            "|[{'id': 99, 'name...|              4.25|\n",
            "|[{'id': 53, 'name...|              4.25|\n",
            "|[{'id': 28, 'name...|              4.25|\n",
            "|[{'id': 10749, 'n...| 4.213932576813326|\n",
            "|[{'id': 18, 'name...|4.2131118634504165|\n",
            "|[{'id': 18, 'name...| 4.199924604171902|\n",
            "|[{'id': 14, 'name...|4.1806621880998085|\n",
            "|[{'id': 18, 'name...| 4.166666666666667|\n",
            "|[{'id': 18, 'name...| 4.152347687892122|\n",
            "|[{'id': 16, 'name...| 4.150013762730525|\n",
            "|[{'id': 18, 'name...| 4.135950817381585|\n",
            "|[{'id': 10770, 'n...|4.1306878306878305|\n",
            "|[{'id': 28, 'name...| 4.130216013452335|\n",
            "|[{'id': 18, 'name...| 4.114169927333706|\n",
            "|[{'id': 9648, 'na...|  4.11226428884666|\n",
            "|[{'id': 18, 'name...| 4.109830097087379|\n",
            "|[{'id': 28, 'name...| 4.104114395999649|\n",
            "|[{'id': 28, 'name...| 4.086393827822901|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from pyspark.sql.functions import to_timestamp, date_format, year, month\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "from pyspark.sql.functions import from_unixtime, col\n",
        "\n",
        "# Convert the timestamp column to timestamp data type.\n",
        "ratings_df = ratings_df.withColumn(\"timestamp\", to_timestamp(F.col(\"timestamp\"), 'yyyy-MM-dd HH:mm:ss'))\n",
        "\n",
        "# Extract year and month from the timestamp\n",
        "ratings_df = ratings_df.withColumn(\"year\", year(F.col(\"timestamp\"))).withColumn(\"month\", month(F.col(\"timestamp\")))\n",
        "\n",
        "# Total ratings per year\n",
        "ratings_by_year = ratings_df.groupBy(\"year\").count().orderBy(\"year\")\n",
        "ratings_by_year.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOyh_WHc5PYm",
        "outputId": "9107f8ac-9129-4bac-e4e0-dfdd0bcf0d36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|year|count|\n",
            "+----+-----+\n",
            "|1996|23147|\n",
            "|1997| 9170|\n",
            "|1998| 3700|\n",
            "|1999|13457|\n",
            "|2000|23399|\n",
            "|2001|13582|\n",
            "|2002|11849|\n",
            "|2003|13309|\n",
            "|2004|14835|\n",
            "|2005|19152|\n",
            "|2006|15971|\n",
            "|2007|22723|\n",
            "|2008|14243|\n",
            "|2009|14097|\n",
            "|2010|15200|\n",
            "|2011|11311|\n",
            "|2012| 9242|\n",
            "|2013| 6811|\n",
            "|2014| 5868|\n",
            "|2015|19147|\n",
            "+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}